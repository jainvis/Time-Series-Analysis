---
title: "Analysis of Bitcoin Daily Closing Price"
author: "Akshay Sharma & Vishesh Jain"
date: "13 May 2018"
output:
  ioslides_presentation:
    highlight: haddock
    widescreen: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## INTRODUCTION {.smaller}

Any form of currency that only exists digitally relying on cryptography to prevent counterfeiting and fraudulent transactions is defined as cryptocurrency. Bitcoin was the very first Cryptocurrency. It was invented in 2009 by an anonymous person, or group of people, who referred to themselves as Satoshi Nakamoto.

In April 2013, the value of 1 bitcoin (BTC) was around 100 USD. At the beginning of 2017 its value was 1,022 USD and by the 15th of December it was worth 19,497 USD. As of the 3rd of March 2018, 1 BTC sells for 11,513 USD. So, the time series analysis of bitcoin series is very challenging.

The challenge is to find the best fitting model to the given cryptocurrency series and Predict the value of bitcoin for next **10-days**. The data-set used is the daily closing price of bitcoin from **27-April-2013** to **03-March-2018**. 
The data has been gathered from <https://coinmarketcap.com/>

**NOTE**: The performance of the model will be measured using **Mean-Absolute Scaled Error (MASE)**. We will use the real values of bitcoin for 10 days of forecast period **(4 to 13-March-2018)**.

```{r echo=FALSE}
BoxCoxSearch = function(y, lambda=seq(-3,3,0.01), 
                        m= c("sf", "sw","ad" ,"cvm", "pt", "lt", "jb"), plotit = T, verbose = T){
  N = length(m)
  BC.y = array(NA,N)
  BC.lam = array(NA,N)
  for (i in 1:N){
    if (m[i] == "sf"){
      wrt = "Shapiro-Francia Test"
    } else if (m[i] == "sw"){
      wrt = "Shapiro-Wilk  Test"
    } else if (m[i] == "ad"){
      wrt = "Anderson-Darling Test"
    } else if (m[i] == "cvm"){
      wrt = "Cramer-von Mises Test"
    } else if (m[i] == "pt"){
      wrt = "Pearson Chi-square Test"
    } else if (m[i] == "lt"){
      wrt = "Lilliefors Test"
    } else if (m[i] == "jb"){
      wrt = "Jarque-Bera Test"
    } 
    
    print(paste0("------------- ",wrt," -------------"))
    out = tryCatch({boxcoxnc(y, method = m[i], lam = lambda, lambda2 = NULL, plot = plotit, alpha = 0.05, verbose = verbose)
                   BC.lam[i] = as.numeric(out$lambda.hat)}, 
                   error = function(e) print("No results for this test!"))
    
  }
  return(list(lambda = BC.lam,p.value = BC.y))
}
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(TSA)
library(dplyr)
library(FSAdata)
library(readr)
library(knitr)
library(tseries)
library(AID) # For the boxcoxnc() function
library(nortest)
library(lmtest)
library(forecast)
library(fGarch)

#Reading Data in R-Workspace
coin = read.csv("~/Bitcoin_Historical_Price.csv")
```

## DATA EXPLORATION - TIME SERIES PLOT

```{r echo=FALSE, fig.align='center'}
bitcoin = coin$Close # Taking closing Price from the data frame
plot(bitcoin, type = "l",xlab="Days",ylab = "Bitcoin Prices in USD",
     main = "Figure 1: Time Series plot of Bitcoin Daily Closing Prices \n from 27-04-2013 to 03-03-2018",
     col="blue")
grid()
```

## {.smaller}

As we can see in this plot, there can be two different time series in the data

The purpose of this project is to predict future values, therefore, we will take the series after 1000 days i.e. from 21-January-2016.

```{r echo=TRUE}
bitcoin = bitcoin[1000:1772] # Taking closing prices from 1000 day (21-01-2016)
```
```{r echo=FALSE, fig.align='center'}
plot(bitcoin, type = "l",xlab="Days",ylab = "Bitcoin Prices in USD",
     main = "Figure 2: Time Series plot of Bitcoin Daily Closing Prices \n from 21-01-2016 to 03-03-2018",
     col="blue")
grid()
```

## NORMALITY DISTRIBUTION OF SERIES {.smaller}

We can clearly see through figures 3 & 4, that the distribution of the series is not normal, this is a right-skewed distribution.

```{r echo=FALSE, fig.align='center'}
par(mfrow = c(1,2))
qqnorm(bitcoin,ylab="Sample Quantiles", 
       main = "Figure 3: Normal Q-Q Plot",
       cex.main = 0.8, pch=20, col="blue")
qqline(bitcoin,col = 2, lwd = 1, lty = 2)
grid()

hist(bitcoin, freq = F, breaks = 7,
     main = "Figure 4: Histogram Plot",
     xlab = "bitcoins", col="lightblue")
grid()
```

## {.smaller}

Therefore, we will employ a Box-Cox Search method to find the best value of lambda and transform the series using:

$$\mathbf{X_t} = \left(\frac{X^\lambda-1}{\lambda} \right)$$

```{r echo=TRUE, results='hide', warning=FALSE, message=FALSE}
BoxCoxSearch(bitcoin, plotit = F) # Using normality tests to find lambda
```

Through above search, we found $$\mathbf{\lambda} = -0.5$$

We will transform the series using the given formula:

```{r echo=TRUE}
bit = (bitcoin^(-0.5)-1)/(-0.5)
```

## {.smaller}

We can see that the distribution of the series has considerably improved after the transformation. As per figure 5, data is aligned with the normality line except for fat tails which is expected in a financial time-series.

```{r echo=FALSE, fig.align='center'}
par(mfrow = c(1,2))
qqnorm(bit,ylab="Sample Quantiles", 
       main = "Figure 5: Normal Q-Q Plot",
       cex.main = 0.8, pch=20, col="blue")
qqline(bit,col = 2, lwd = 1, lty = 2)
grid()

hist(bit, freq = F, breaks=5,
     main = "Figure 6: Histogram Plot",
     xlab = "bitcoins", col="lightblue")
grid()
```

## BOX-COX TRANSFORMED SERIES

```{r echo=FALSE, fig.align='center'}
plot(bit, type = "l",xlab="Days",ylab = "Transformed Bitcoin Prices in USD",
     main = "Figure 7: Time Series plot of Transformed \n Bitcoin Daily Closing Prices from 21-01-2016 to 03-03-2018",
     col="blue")
grid()
```

***
**Observations**:

  - *Trend*: There is a clear upward trend in the series
  - *Seasonality*: Seasonality is not clear in the series
  - *Behavior*: This could be auto-regressive or moving-average or both
  - *Variance*: Change in variance might not be present
  
Following the given observations, we will move ahead with ARIMA/ SARIMA modeling of the series.

Using ts() function from TSA package, the given series is converted to a time series object.

```{r echo=TRUE}
bit1 = ts(log(bit)) #Log is used to control the change in variance (if any)
```

## STATIONARITY & CORRELATION IN THE SERIES {.smaller}

As seen in figure 8 & 9, there is ordinary trend in the series. Therefore, we will proceed with first difference of the series.
```{r echo=FALSE, fig.align='center'}
## No-Differencing
par(mfrow=c(1,2))
acf(bit1, lag.max = 50, main="Figure 8: ACF Plot of \n Transformed Series")
pacf(bit1, lag.max = 50, main="Figure 9: PACF of \n Transformed Series")
```

## {.smaller}

```{r echo=TRUE}
bitd = diff(bit1)
```

From figure 10 & 11, we can confirm that there is no ordinary trend left in the series. Also, there are no significant AR/MA lags. However, we can see significant lags at period 6.

**Note**: This could be a sign of $weak seasonality$ in the series

```{r echo=FALSE, fig.align='center'}
## No-Differencing
par(mfrow=c(1,2))
acf(bitd,lag.max=24, main="Figure 10: ACF Plot of \n Transformed Series")
pacf(bitd, lag.max=24, main="Figure 11: PACF of \n Transformed Series")
```

```{r echo=FALSE, results='hide'}
# First Difference
adf.test(bitd)
kpss.test(bitd, null = "Trend", lshort = F)
```

```{r echo=FALSE, results='hide'}
Box.test(bitd,  type = "Ljung-Box")
```


## ARIMA/ SARIMA MODELING {.smaller}

**No-Differencing** : ADF and KPSS test shows that the series is not stationary

**First-Difference** : ADF and KPSS test shows that the series is stationary now

Remember in ACF & PACF plots of the first-differenced series, there were no significant lags. Therefore, we will use **EACF** and **BIC** to find the suitable candidate models.

```{r echo=FALSE, results='hide'}
eacf(bitd)
```

**EACF** - Possible candidate models are: $ARIMA(1,1,1), ARIMA(0,1,1) ARIMA(2,1,2)$

**BIC** - Possible models are: $ARIMA(3,1,6), ARIMA(6,1,6), ARIMA(2,1,3), ARIMA(2,1,6)$

```{r echo=FALSE, fig.align='center', warning=FALSE, results='hide'}
BICplot = armasubsets(y=bitd,nar=13,nma=13 ,y.name='test',ar.method='ols')
# plot(BICplot)
# title("Figure 12: BIC Plot of the differenced Series",line = 6)
```

## MODEL FITTING {.smaller}

Through model fitting and coefficient testing, we found that ARIMA(2,1,2) is the best fit model.

After conducting the coefficient test fo ARIMA(2,1,2), we found 'NA' in the standard error and z-value of the model, which means indicates towards seasonality in the data.

We will next explore the seaonal model.

```{r echo=TRUE}
m.arima = arima(bit1, order = c(2,1,2))
res.arima = m.arima$residuals
coeftest(m.arima)
```

## {.smaller}

This was modeled using a SARIMA(2,1,2)X(0,0,1)<sub>6</sub>

```{r echo=TRUE}
m1 = Arima(bit1, order = c(2,1,2), seasonal = list(order = c(0,0,1), period = 6))
coeftest(m1)
```

All the parameteres are found to be significant at 5% significance level.

## RESIDUAL ANALYSIS {.smaller}

```{r eacho=FALSE, fig.align='center', warning=FALSE, message=FALSE, fig.height=6}
residual.analysis <- function(model, std = TRUE,start = 2, class = c("ARIMA","GARCH","ARMA-GARCH")[1]){
  # If you have an output from arima() function use class = "ARIMA"
  # If you have an output from garch() function use class = "GARCH"
  # If you have an output from ugarchfit() function use class = "ARMA-GARCH"
  library(TSA)
  library(FitAR)
  if (class == "ARIMA"){
    if (std == TRUE){
      res.model = rstandard(model)
    }else{
      res.model = residuals(model)
    }
  }else if (class == "GARCH"){
    res.model = model$residuals[start:model$n.used]
  }else if (class == "ARMA-GARCH"){
    res.model = model@fit$residuals
  }else {
    stop("The argument 'class' must be either 'ARIMA' or 'GARCH' ")
  }
  par(mfrow=c(3,2))
  plot(res.model,type='o',ylab='Standardised residuals', main="Time series plot of standardised residuals")
  abline(h=0)
  hist(res.model,main="Histogram of standardised residuals")
  acf(res.model,main="ACF of standardised residuals")
  pacf(res.model,main="PACF of standardised residuals")
  qqnorm(res.model,main="QQ plot of standardised residuals")
  qqline(res.model, col = 2)
  k=0
  LBQPlot(res.model, lag.max = 30, StartLag = k + 1, k = 0, SquaredQ = FALSE)
}
residual.analysis(m1)
```


```{r echo=FALSE, results='hide'}
shapiro.test(residuals(m1))
```

## GARCH MODELING {.smaller}

Although, the residuals of the fitted model shows no auto-correlation, there might be presence of **volatility-clustering** in the series. We will perform a test to check the presence of this clustering.

```{r echo=FALSE, fig.align='center', fig.height=3}
bitr = residuals(m1)
McLeod.Li.test(y =bitr)
title("Figure 13: Mc Leod Li Test of Residuals")
```

The McLeod Li Test confirms the presence of volatility clustering at all lags. To model this clustering, we will use absolute and squared residuals and analyse ACF, PACF & EACF for possible GARCH models.

## ACF & PACF - ABSOLUTE & SQUARE RESIDUALS

```{r echo=FALSE, fig.align='center', results='hide'}
par(mfrow = c(2,2))
acf(abs(bitr), main="Figure 14: Absolute Residuals ACF")
acf(abs(bitr), type = "partial", main="Figure 15: Absolute Residuals PACF")
acf((bitr)^2, main="Figure 16: Squared Residuals ACF")
acf((bitr)^2, type = "partial", main="Figure 17: Squared Residuals PACF")
```

We can see many significant lags from the ACF & PACF plots. The $p$ value found from EACF of absolute residuals is 1,2 and from EACF of squared residuals is 2,3.

```{r echo=FALSE}
print("----Absolute Residuals EACF-----")
eacf(abs(bitr)) #p = 1,2
print("----Squared Residuals EACF-----")
eacf(abs(bitr)) #p = 2,3
```

## GARCH MODELS

Through ACF, PACF & EACF of the absolute and squared residuals, we found possible models as; GARCH(1,2), GARCH(2,2), GARCH(1,3), GARCH(2,3)
  
After, comparing significance of the coefficients and AIC values of the possible candidate models, we found GARCH(1,2) with **AIC=-2663.847** as the best fitted model for the residuals.

All the parameters are significant at 5% significance level.

```{r echo=TRUE}
m2<- garch(bitr*100, order = c(2,1), trace = F)
# arima_garch_model = ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)), 
#                   mean.model = list(armaOrder = c(1, 0), include.mean = FALSE), 
#                   distribution.model = "norm")
# arima_garch_fit <-ugarchfit(spec=arima_garch_model,data=diff(bit1))
# arima_garch_fit
```

```{r results='hide'}
summary(m2)
```

## SARIMA(2,1,2)X(0,0,1)<sub>6</sub> + GARCH(1,2) FORECASTING {.smaller}

To proceed with this, we will first predict the conditional variance for the next 10 days.

```{r echo=FALSE}
g = garchFit(~garch(1,2), bitr*10, include.mean = F , trace=FALSE) # GARCH(1,2) fitting
gpred <- predict(g, n.ahead = 10) # Predicating 10-ahead values
omega = g@fit$matcoef[1,1]
alpha = g@fit$matcoef[2,1]
beta = g@fit$matcoef[3,1]
beta2 = g@fit$matcoef[4,1]
bitrl = as.numeric(bitr)

# Finding the 10-ahead conditional variance using omeaga, alpha and beta using a for-loop
for(i in c(1:10)){
  bitrl[773 + i] = omega + alpha * bitrl[772 + i]^2*gpred$meanError[i] + 
    beta*ifelse(is.na(g@h.t[772 + i]),gpred$standardDeviation[i-1]^2,g@h.t[772 + i]) +
    beta2*ifelse(is.na(g@h.t[771 + i]),gpred$standardDeviation[i-2]^2,g@h.t[771 + i])
}
```

Next, we will forecast the 10-ahead values from SARIMA model and add the conditional variance found earlier. Then we will untransform the predicted values.
```{r echo=FALSE}
bitr1 <- as.numeric(bit1)

# Predicting the 10-ahead values from SARIMA model
kk <- forecast(m1, h = 10)
bitr1 <- c(bitr1, kk$mean)

# Adding conditional variance to the forecasted values from SARIMA model
bitr1[774:783]<- bitr1[774:783] + bitrl[774:783]/10

# Untransforming the forecasted values
bitrl.1<-exp(bitr1) # For Log Transformation
bitrl.2<-(bitrl.1*(-0.5) + 1)^(-2) # For Box-Cox Transformation
```

```{r, fig.align='center', fig.height=4}
plot(ts(bitrl.2, start = 1), col="blue", ylab="Bitcoin Prices in USD", xlab="Days") 
lines(ts(as.vector(bitrl.2[774:783]), start = 774), 
      col="red", type="l",lwd=3)
title("Forecasted Time-Series Plot of Bitcoin Daily Price Values \n from 21-01-2016 to 13-03-2018")
legend(50, 18000, legend=c("Predicted", "Given"),
       col=c("red", "blue"), lty=1:1,lwd = 3:1, cex=0.8)
grid()
```

## PERFORMANCE MEASURE {.smaller}

As mentioned earlier, **MASE** will be used to check the performance of the model. The series as found during the analysis is seasonal, therefore, **MASE** function for seasonal series will be used.


$$\mathbf{MASE} = \frac{1}{T}\sum_{t=1}^{T}\left( \frac{\lvert{e_t}\rvert}{\frac{1}{T-m}\sum_{t=m+1}^T\lvert Y_t - Y_{t-m}\rvert}\right)$$
$m = 6 : seasonal period$

```{r echo=FALSE}
realVal = read.csv("~/Bitcoin_Prices_Forecasts.csv")

MASE = function(observed , fitted ){
  
  Y.t = observed
  n = length(fitted)
  e.t = Y.t - fitted
  sum = 0 
  for (i in 7:n){
    sum = sum + abs(Y.t[i] - Y.t[i-6] )
  }
  q.t = e.t / (sum*(n-7)/(n-1))
  MASE = data.frame( MASE = mean(abs(q.t)))
  return(list(MASE = MASE))
}

```

```{r echo=TRUE}
observed = as.numeric(realVal$Closing.price)
fitted = as.numeric(bitrl.2[774:783])

MASE(observed, fitted)
```

**MASE = 0.7261805**